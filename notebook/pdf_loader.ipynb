{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "299c1034",
   "metadata": {},
   "source": [
    "### RAG Pipeline- Data Ingestion to Vector DB Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f1390f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c85a86",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19502001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 PDF files to Process\n",
      "\n",
      "Processing: jobData.pdf\n",
      "Loaded 1 pages\n",
      "\n",
      "Processing: Sandra-Ubenyi.pdf\n",
      "Loaded 2 pages\n",
      "\n",
      "Total documents loaded: 3\n"
     ]
    }
   ],
   "source": [
    "### Read all PDF inside the directory\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    \"\"\" Process all PDF files in a directory \"\"\"\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "\n",
    "    # Find all PDF files recursively\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "\n",
    "    print(f\"Found {len(pdf_files)} PDF files to Process\")\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nProcessing: {pdf_file.name}\")\n",
    "        try:\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "\n",
    "            # Add source information to metadata\n",
    "            for doc in documents:\n",
    "                doc.metadata['source_file'] = pdf_file.name\n",
    "                doc.metadata['file_type'] = 'pdf'\n",
    "            \n",
    "            all_documents.extend(documents)\n",
    "            print(f\"Loaded {len(documents)} pages\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"X Error: {e}\")\n",
    "\n",
    "    print(f\"\\nTotal documents loaded: {len(all_documents)}\")\n",
    "    return all_documents\n",
    "\n",
    "all_pdf_documents = process_all_pdfs(\"../data/pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d4b3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Text splitting getting to chunks\n",
    "\n",
    "def split_documents(documents, chunk_size=1000, chunk_overlap=200):\n",
    "    ### Split documents into smaller chunks for better RAG performance ###\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size= chunk_size,\n",
    "        chunk_overlap= chunk_overlap,\n",
    "        length_function= len,\n",
    "        separators= [\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "\n",
    "    if split_docs:\n",
    "        print(f\"\\n Example chunk: \")\n",
    "        print(f\"Content: {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "        \n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "282caa78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 3 documents into 5 chunks\n",
      "\n",
      " Example chunk: \n",
      "Content: Greg Udogu\n",
      "SQL Database Engineer\n",
      "Company: Bootspace Technology\n",
      "Start Date: Mon Jul 14 2025\n",
      "End Date: Tue Nov 18 2025\n",
      "Job Type: Gig\n",
      "Work Mode: Remote\n",
      "Skills & Requirements:\n",
      "SQL, Database Design...\n",
      "Metadata: {'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2025-07-15T15:50:37+00:00', 'source': '../data/pdf/jobData.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'jobData.pdf', 'file_type': 'pdf'}\n"
     ]
    }
   ],
   "source": [
    "chunks= split_documents(all_pdf_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30a6db16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2025-07-15T15:50:37+00:00', 'source': '../data/pdf/jobData.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'jobData.pdf', 'file_type': 'pdf'}, page_content='Greg Udogu\\nSQL Database Engineer\\nCompany: Bootspace Technology\\nStart Date: Mon Jul 14 2025\\nEnd Date: Tue Nov 18 2025\\nJob Type: Gig\\nWork Mode: Remote\\nSkills & Requirements:\\nSQL, Database Design'),\n",
       " Document(metadata={'producer': 'Apache FOP Version 2.3', 'creator': 'Indeed Resume', 'creationdate': '2025-11-28T07:41:18-06:00', 'title': 'Indeed Resume', 'author': 'Indeed', 'keywords': 'Indeed Resume', 'source': '../data/pdf/Sandra-Ubenyi.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1', 'source_file': 'Sandra-Ubenyi.pdf', 'file_type': 'pdf'}, page_content='SANDRA UBENYI\\nPort Harcourt, Rivers\\nubenyisandra@gmail.com\\n• Detail-oriented administrative professional with 4+ years’ experience providing scheduling, client\\ncommunication, documentation, and organizational support.\\n• Skilled in managing calendars, drafting correspondence, preparing reports, and coordinating meetings.\\n• Adept at supporting executives and teams in fast-paced environments.\\nWork Experience\\nPUBLIC HEALTH WORKER\\nInstitute of Human Virology, Nigeria (IHVN)-Port Harcourt\\nOctober 2020 to Present\\n• Manage scheduling and calendar coordination, including setting appointments and planning internal\\nand external meetings.\\n• Interface and communicate with clients and stakeholders, ensuring professional, timely, and accurate\\ninformation exchange.\\n• Conduct client follow-ups to confirm appointments, clarify needs, and maintain strong ongoing\\nengagement.\\n• Update and maintain client information within the Electronic Medical Records (EMR) system to ensure\\ndata accuracy and compliance.'),\n",
       " Document(metadata={'producer': 'Apache FOP Version 2.3', 'creator': 'Indeed Resume', 'creationdate': '2025-11-28T07:41:18-06:00', 'title': 'Indeed Resume', 'author': 'Indeed', 'keywords': 'Indeed Resume', 'source': '../data/pdf/Sandra-Ubenyi.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1', 'source_file': 'Sandra-Ubenyi.pdf', 'file_type': 'pdf'}, page_content='engagement.\\n• Update and maintain client information within the Electronic Medical Records (EMR) system to ensure\\ndata accuracy and compliance.\\n• Organize, schedule, and facilitate monthly Strategic Continuous Quality Improvement (CQI) meetings\\nto support alignment with quarterly Key Performance Indicators (KPIs) for the assigned health facility.\\n• Draft professional emails, memos, and business communications on behalf of management and the\\norganization.\\n• Perform online research and compile findings into structured spreadsheets and summary reports to\\nsupport decision-making.\\n• Prepare meeting materials, including agendas, briefing documents, minutes, and presentation slides.\\n• Assist with creative communication tasks, such as writing content for newsletters, media updates, and\\ninternal announcements.\\n• Handle administrative support functions, including document management, filing, and ensuring timely\\ncompletion of operational and project-related tasks.\\nEducation'),\n",
       " Document(metadata={'producer': 'Apache FOP Version 2.3', 'creator': 'Indeed Resume', 'creationdate': '2025-11-28T07:41:18-06:00', 'title': 'Indeed Resume', 'author': 'Indeed', 'keywords': 'Indeed Resume', 'source': '../data/pdf/Sandra-Ubenyi.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1', 'source_file': 'Sandra-Ubenyi.pdf', 'file_type': 'pdf'}, page_content='internal announcements.\\n• Handle administrative support functions, including document management, filing, and ensuring timely\\ncompletion of operational and project-related tasks.\\nEducation\\nGUIDANCE & COUNSELLING (BSC)\\nBENUE STATE, UNIVERSITY-Makurdi\\nAugust 2012 to June 2018\\nSkills\\n• Communication skills\\n• Administrative experience\\n• Organizational skills\\n• Time Management and Scheduling'),\n",
       " Document(metadata={'producer': 'Apache FOP Version 2.3', 'creator': 'Indeed Resume', 'creationdate': '2025-11-28T07:41:18-06:00', 'title': 'Indeed Resume', 'author': 'Indeed', 'keywords': 'Indeed Resume', 'source': '../data/pdf/Sandra-Ubenyi.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2', 'source_file': 'Sandra-Ubenyi.pdf', 'file_type': 'pdf'}, page_content='• Travel Cordination\\n• Correspondence Management\\n• Leadership\\n• Microsoft Office\\n• Calender Management\\n• Notion\\n• Customer service')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e83148b",
   "metadata": {},
   "source": [
    "### Embedding and Vector store DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa8bc13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any , Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10e67d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading model all-MiniLM-L6-v2\n",
      "Model loaded successfully. Embedding dimension 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x134662f90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    # Handles document embedding generation\n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "            Initialize the embedding manager\n",
    "\n",
    "            Args:\n",
    "                model_name: Hugging face model name for sentence embeddings\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\" Load the Sentence Transformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Error loading model {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded successfully. Embedding dimension {self.model.get_sentence_embedding_dimension()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {self.model_name}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts\n",
    "\n",
    "        ARGS:\n",
    "        List of text strings to be embedded\n",
    "\n",
    "        Returns:\n",
    "        numpy array of embeddings with shape (len(texts), embedding_ dim)\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        \n",
    "        print(f\"Generating embeddings for {len(texts)} text...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar= True)\n",
    "        print(f\"Generated embeddings with shape {embeddings.shape}\")\n",
    "        return embeddings\n",
    "    \n",
    "    def get_embedding_dimension(self) -> int:\n",
    "        \"\"\"Get the embedding dimension of the model\"\"\"\n",
    "\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        return self.model.get_sentence_embedding_dimension()\n",
    "    \n",
    "\n",
    "## Initializing embedding Manager\n",
    "embedding_manager = EmbeddingManager()\n",
    "embedding_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b1f0b9",
   "metadata": {},
   "source": [
    "#### VECTOR STORE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1679af27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Vector Store initialized. Collection: pdf_documents\n",
      " Existing documents in collection: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x1347aff90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Manages Document embeddings in a ChromaDB Vector store\"\"\"\n",
    "    def __init__(self, collection_name: str = 'pdf_documents', persist_directory: str = \"../data/vector_store\"):\n",
    "        \"\"\"\n",
    "        Initialize the Vector Store\n",
    "\n",
    "        Args:\n",
    "            collection_name: Name of the ChromaDB collection\n",
    "            persist_directory: Directory to persist the vector store\n",
    "        \"\"\"\n",
    "\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        \"\"\" Initialize chromaDB client and collection\"\"\"\n",
    "        try:\n",
    "            #Create persistent chromaDB client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path= self.persist_directory)\n",
    "\n",
    "            #Get or create collections\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name = self.collection_name,\n",
    "                metadata = {\"description\": \"PDF Documents embedding for RAG\"}\n",
    "            )\n",
    "\n",
    "            print(f\" Vector Store initialized. Collection: {self.collection_name}\")\n",
    "            print(f\" Existing documents in collection: {self.collection.count()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing Vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_documents(self, documents: List[any], embeddings: np.ndarray):\n",
    "        \"\"\"\n",
    "        Add documents and their embeddings to the Vector Store\n",
    "\n",
    "        ARGS:\n",
    "            documents: A list of Langchain documents\n",
    "            embeddings: Corresponding embeddings for the documents\n",
    "        \"\"\"\n",
    "\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "\n",
    "        # Prepare Data for ChromaDB\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "\n",
    "\n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # Generate unique IDs\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "\n",
    "            # Prepare Metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata[\"doc_index\"] = i\n",
    "            metadata[\"content_length\"] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            # Document content\n",
    "            documents_text.append(doc.page_content)\n",
    "\n",
    "            # Embedding \n",
    "            embeddings_list.append(embedding.tolist())\n",
    "\n",
    "        # Add to collections\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids = ids,\n",
    "                embeddings = embeddings_list,\n",
    "                metadatas = metadatas,\n",
    "                documents = documents_text\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "            print(f\" Total documents in collection: {self.collection.count()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" Error adding documents to vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "vector_Store = VectorStore()\n",
    "vector_Store   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5a2019f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'PDFKit', 'creator': 'PDFKit', 'creationdate': '2025-07-15T15:50:37+00:00', 'source': '../data/pdf/jobData.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'jobData.pdf', 'file_type': 'pdf'}, page_content='Greg Udogu\\nSQL Database Engineer\\nCompany: Bootspace Technology\\nStart Date: Mon Jul 14 2025\\nEnd Date: Tue Nov 18 2025\\nJob Type: Gig\\nWork Mode: Remote\\nSkills & Requirements:\\nSQL, Database Design'),\n",
       " Document(metadata={'producer': 'Apache FOP Version 2.3', 'creator': 'Indeed Resume', 'creationdate': '2025-11-28T07:41:18-06:00', 'title': 'Indeed Resume', 'author': 'Indeed', 'keywords': 'Indeed Resume', 'source': '../data/pdf/Sandra-Ubenyi.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1', 'source_file': 'Sandra-Ubenyi.pdf', 'file_type': 'pdf'}, page_content='SANDRA UBENYI\\nPort Harcourt, Rivers\\nubenyisandra@gmail.com\\n• Detail-oriented administrative professional with 4+ years’ experience providing scheduling, client\\ncommunication, documentation, and organizational support.\\n• Skilled in managing calendars, drafting correspondence, preparing reports, and coordinating meetings.\\n• Adept at supporting executives and teams in fast-paced environments.\\nWork Experience\\nPUBLIC HEALTH WORKER\\nInstitute of Human Virology, Nigeria (IHVN)-Port Harcourt\\nOctober 2020 to Present\\n• Manage scheduling and calendar coordination, including setting appointments and planning internal\\nand external meetings.\\n• Interface and communicate with clients and stakeholders, ensuring professional, timely, and accurate\\ninformation exchange.\\n• Conduct client follow-ups to confirm appointments, clarify needs, and maintain strong ongoing\\nengagement.\\n• Update and maintain client information within the Electronic Medical Records (EMR) system to ensure\\ndata accuracy and compliance.'),\n",
       " Document(metadata={'producer': 'Apache FOP Version 2.3', 'creator': 'Indeed Resume', 'creationdate': '2025-11-28T07:41:18-06:00', 'title': 'Indeed Resume', 'author': 'Indeed', 'keywords': 'Indeed Resume', 'source': '../data/pdf/Sandra-Ubenyi.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1', 'source_file': 'Sandra-Ubenyi.pdf', 'file_type': 'pdf'}, page_content='engagement.\\n• Update and maintain client information within the Electronic Medical Records (EMR) system to ensure\\ndata accuracy and compliance.\\n• Organize, schedule, and facilitate monthly Strategic Continuous Quality Improvement (CQI) meetings\\nto support alignment with quarterly Key Performance Indicators (KPIs) for the assigned health facility.\\n• Draft professional emails, memos, and business communications on behalf of management and the\\norganization.\\n• Perform online research and compile findings into structured spreadsheets and summary reports to\\nsupport decision-making.\\n• Prepare meeting materials, including agendas, briefing documents, minutes, and presentation slides.\\n• Assist with creative communication tasks, such as writing content for newsletters, media updates, and\\ninternal announcements.\\n• Handle administrative support functions, including document management, filing, and ensuring timely\\ncompletion of operational and project-related tasks.\\nEducation'),\n",
       " Document(metadata={'producer': 'Apache FOP Version 2.3', 'creator': 'Indeed Resume', 'creationdate': '2025-11-28T07:41:18-06:00', 'title': 'Indeed Resume', 'author': 'Indeed', 'keywords': 'Indeed Resume', 'source': '../data/pdf/Sandra-Ubenyi.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1', 'source_file': 'Sandra-Ubenyi.pdf', 'file_type': 'pdf'}, page_content='internal announcements.\\n• Handle administrative support functions, including document management, filing, and ensuring timely\\ncompletion of operational and project-related tasks.\\nEducation\\nGUIDANCE & COUNSELLING (BSC)\\nBENUE STATE, UNIVERSITY-Makurdi\\nAugust 2012 to June 2018\\nSkills\\n• Communication skills\\n• Administrative experience\\n• Organizational skills\\n• Time Management and Scheduling'),\n",
       " Document(metadata={'producer': 'Apache FOP Version 2.3', 'creator': 'Indeed Resume', 'creationdate': '2025-11-28T07:41:18-06:00', 'title': 'Indeed Resume', 'author': 'Indeed', 'keywords': 'Indeed Resume', 'source': '../data/pdf/Sandra-Ubenyi.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2', 'source_file': 'Sandra-Ubenyi.pdf', 'file_type': 'pdf'}, page_content='• Travel Cordination\\n• Correspondence Management\\n• Leadership\\n• Microsoft Office\\n• Calender Management\\n• Notion\\n• Customer service')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 5 text...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53e05931b564c70a708a5ec256b01d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape (5, 384)\n",
      "Adding 5 documents to vector store...\n",
      "Successfully added 5 documents to vector store\n",
      " Total documents in collection: 5\n"
     ]
    }
   ],
   "source": [
    "### Convert the text to embeddings\n",
    "texts = [doc.page_content for doc in chunks]\n",
    "texts\n",
    "\n",
    "## Generate Embeddings\n",
    "embeddings = embedding_manager.generate_embeddings(texts)\n",
    "\n",
    "## Store in Vector Store\n",
    "vector_Store.add_documents(chunks, embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
